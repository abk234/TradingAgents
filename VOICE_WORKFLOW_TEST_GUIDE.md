# Voice Workflow Testing Guide

## âœ… Integration Test Results

All voice workflow components have been verified:

- âœ… **Ticker Extraction Logic** - Correctly extracts tickers from voice input
- âœ… **TTS Text Preparation** - Properly formats analysis text for speech synthesis
- âœ… **API Client Logic** - Correctly handles base64 audio conversion
- âœ… **VoiceInput Integration** - Properly integrated in DirectAnalysis component
- âœ… **Voice Output Integration** - Properly integrated in AnalysisResults component

## Complete Voice Workflow

The voice workflow consists of three main steps:

### Step 1: Voice Input (STT - Speech-to-Text)

**Location:** `web-app/components/DirectAnalysis.tsx`

**How it works:**
1. User clicks the microphone button next to the ticker input field
2. Browser requests microphone permission (if not already granted)
3. User speaks (e.g., "AAPL" or "analyze NVDA")
4. Audio is streamed via WebSocket to `/voice/ws` endpoint
5. Backend transcribes audio using faster-whisper
6. Transcription is sent back to frontend
7. Ticker is extracted from transcription using regex pattern matching
8. Extracted ticker is populated in the input field

**Test Cases:**
- âœ… "AAPL" â†’ Extracts "AAPL"
- âœ… "analyze AAPL" â†’ Extracts "AAPL"
- âœ… "NVDA stock analysis" â†’ Extracts "NVDA"
- âœ… "TSLA" â†’ Extracts "TSLA"

### Step 2: Processing (Stock Analysis)

**Location:** `web-app/components/DirectAnalysis.tsx` â†’ `useAnalysis` hook â†’ Backend API

**How it works:**
1. User clicks "Run Analysis" button
2. Form submits with ticker and selected analysts
3. Frontend sends request to `/chat` endpoint
4. Backend orchestrates multi-agent analysis:
   - Market Analyst
   - News Analyst
   - Social Media Analyst
   - Fundamentals Analyst
   - Bull & Bear Researchers
   - Research Manager
   - Risk Manager
5. Analysis result is streamed back to frontend
6. Result is displayed in `AnalysisResults` component

**Expected Duration:** 30-90 seconds for full analysis

### Step 3: Voice Output (TTS - Text-to-Speech)

**Location:** `web-app/components/AnalysisResults.tsx`

**How it works:**
1. User clicks "Play Voice" button in the analysis results header
2. Frontend extracts text based on current tab:
   - **Summary tab:** Executive summary
   - **Analysts tab:** All analyst reports
   - **Debate tab:** Bullish and bearish cases
   - **Decision tab:** Final recommendation
3. Text is sent to `/voice/synthesize` endpoint with `return_base64=true`
4. Backend synthesizes speech using Coqui TTS (or fallback to pyttsx3)
5. Audio is returned as base64 string
6. Frontend converts base64 to Blob with `audio/wav` MIME type
7. Audio is played using HTML5 Audio API
8. User can stop playback by clicking "Stop Voice" button

**Features:**
- âœ… Tab-aware: Reads content from the currently active tab
- âœ… Professional tone: Uses "professional" emotional tone
- âœ… Error handling: Gracefully handles API errors
- âœ… Audio cleanup: Properly revokes object URLs on unmount

## Manual Testing Steps

### Prerequisites

1. **Backend Server Running:**
   ```bash
   python -m tradingagents.api.main
   ```
   Should be available at: http://localhost:8005

2. **Frontend Server Running:**
   ```bash
   cd web-app
   npm run dev -- -p 3005
   ```
   Should be available at: http://localhost:3005

3. **API Key Configured:**
   - Set in browser localStorage (Settings page or login)
   - Or set in `.env` file as `API_KEY`

4. **Dependencies Installed:**
   - TTS library: `pip install TTS pyttsx3`
   - faster-whisper: `pip install faster-whisper` (for STT)

### Test Procedure

#### Test 1: Voice Input (STT)

1. Open http://localhost:3005
2. Navigate to **Direct Analysis** view
3. Locate the ticker input field
4. Click the **microphone button** (ðŸŽ¤) next to the input
5. **Grant microphone permission** when prompted by browser
6. Say a ticker symbol clearly (e.g., "AAPL" or "analyze NVDA")
7. Click **Stop** when done speaking
8. **Expected:** Ticker should appear in the input field

**Troubleshooting:**
- If microphone permission is denied, check browser settings
- If transcription fails, check browser console for errors
- Verify WebSocket connection to `/voice/ws` is established

#### Test 2: Full Analysis Processing

1. After voice input populates ticker (or manually enter ticker)
2. Select analyst agents (Market, Social, News, Fundamentals)
3. Click **Run Analysis** button
4. Wait for analysis to complete (30-90 seconds)
5. **Expected:** Analysis results should appear with tabs (Summary, Analysts, Debate, Decision)

**Troubleshooting:**
- If analysis times out, check backend logs
- Verify database connection if using persistent storage
- Check API key is valid

#### Test 3: Voice Output (TTS)

1. After analysis completes, locate the **Play Voice** button in the header
2. Ensure you're on a tab with content (Summary, Analysts, Debate, or Decision)
3. Click **Play Voice** button
4. **Expected:** 
   - Button changes to "Stop Voice"
   - Audio playback starts
   - Analysis is read aloud in professional tone
5. Click **Stop Voice** to pause playback
6. Switch to different tabs and click **Play Voice** again
7. **Expected:** Different content is read based on active tab

**Troubleshooting:**
- If "file does not start with RIFF id" error: This was fixed in the API client
- If no audio plays: Check browser console for errors
- If audio is slow: First synthesis takes 5-10 seconds (model loading)
- Verify TTS libraries are installed: `pip list | grep -i tts`

## Automated Testing

### Run Integration Tests

```bash
python3 test_voice_integration.py
```

This tests:
- Ticker extraction logic
- TTS text preparation
- API client structure
- Component integration

### Run API Tests

```bash
# Test voice synthesis API
python3 test_voice_api.py

# Test complete workflow (requires running server)
python3 test_voice_workflow.py
```

## Expected Behavior Checklist

### Voice Input (STT)
- [ ] Microphone button appears next to ticker input
- [ ] Clicking button requests microphone permission
- [ ] Recording starts when permission granted
- [ ] Transcription appears in input field
- [ ] Ticker is correctly extracted from transcription
- [ ] Error messages appear for permission issues

### Processing
- [ ] Analysis request is sent correctly
- [ ] Loading state shows during analysis
- [ ] Active tools are displayed during processing
- [ ] Analysis results appear when complete
- [ ] All tabs (Summary, Analysts, Debate, Decision) have content

### Voice Output (TTS)
- [ ] "Play Voice" button appears in results header
- [ ] Button changes to "Stop Voice" during playback
- [ ] Audio plays correctly
- [ ] Different tabs produce different audio content
- [ ] Stop button pauses playback
- [ ] Audio cleanup works (no memory leaks)

## Known Issues & Solutions

### Issue: "file does not start with RIFF id"
**Status:** âœ… FIXED
**Solution:** API client now uses base64 format and converts to Blob correctly

### Issue: Microphone permission denied
**Solution:** 
1. Check browser address bar for microphone icon
2. Click icon and select "Allow"
3. Refresh page and try again

### Issue: Slow TTS synthesis
**Expected:** First synthesis takes 5-10 seconds (model loading)
**Solution:** This is normal. Subsequent synthesis is faster (1-3 seconds)

### Issue: No audio playback
**Solution:**
1. Check browser console for errors
2. Verify backend is running on port 8005
3. Verify API key is set correctly
4. Check TTS libraries are installed

## Technical Details

### API Endpoints

- **STT (WebSocket):** `ws://localhost:8005/voice/ws`
- **STT (POST):** `POST /voice/transcribe`
- **TTS:** `POST /voice/synthesize?text={text}&tone={tone}&return_base64=true`

### Component Files

- **VoiceInput:** `web-app/components/VoiceInput.tsx`
- **DirectAnalysis:** `web-app/components/DirectAnalysis.tsx`
- **AnalysisResults:** `web-app/components/AnalysisResults.tsx`
- **API Client:** `web-app/lib/api/client.ts`

### Backend Files

- **API Endpoints:** `tradingagents/api/main.py`
- **TTS Engine:** `tradingagents/voice/tts_engine.py`
- **STT Engine:** `tradingagents/voice/stt_engine.py` (if exists)

## Success Criteria

âœ… **Complete workflow works when:**
1. User can speak ticker and it appears in input field
2. Analysis completes successfully
3. User can hear analysis results read aloud
4. All three steps work together seamlessly

âœ… **Integration verified:**
- All components are properly connected
- Error handling is in place
- Audio format is correct (WAV with RIFF header)
- State management works correctly

